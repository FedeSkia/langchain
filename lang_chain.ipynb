{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bd14b4-4788-45f4-bde1-7a320a5df79f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-ollama in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.68)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain) (0.4.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.1 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain-ollama) (0.5.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: anyio in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/federicoconoci/anaconda3/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09dffbf3-cfe6-49d4-a17f-d792f91fcd8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 0.3.26\n"
     ]
    }
   ],
   "source": [
    "#Verify installation\n",
    "import langchain\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5eb62-2170-4653-ad24-37f3603eaf73",
   "metadata": {},
   "source": [
    "install ollama using docker compose:\n",
    "version: '3.8'\n",
    "services:\n",
    "  ollama:\n",
    "    image: ollama/ollama\n",
    "    container_name: ollama\n",
    "    ports:\n",
    "      - \"11434:11434\"\n",
    "    volumes:\n",
    "      - ollama:/root/.ollama\n",
    "    restart: unless-stopped\n",
    "\n",
    "volumes:\n",
    "  ollama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6663fc42-2df1-4d37-a658-ffef06d72f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Verifica che Ollama sia in esecuzione\n",
    "llm = OllamaLLM(model=\"llama3.1:8b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd531623-2cb1-490e-a2f7-19b0642d33af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a computer program, so I don't have feelings like humans do. But thank you for asking! How can I help you today? Do you have any questions or topics you'd like to discuss?\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d76e573d-b03a-4511-868b-5b64eac86544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith and LangChain are both research frameworks for building and applying large language models (LLMs) to specific tasks, but they serve slightly different purposes and have distinct design goals.\\n\\n**LangChain**: LangChain is a more general-purpose framework designed to facilitate the creation of hybrid intelligence systems. It combines the strengths of large language models with the efficiency and interpretability of traditional software. With LangChain, you can build applications that combine natural language processing (NLP) capabilities with other AI and machine learning techniques.\\n\\n**LangSmith**: LangSmith is another research framework focused on building more robust and accurate language understanding systems. It allows developers to integrate multiple pre-trained language models to create a \"smoothing\" effect. This results in a model that\\'s capable of dealing with ambiguous or open-ended questions and providing more coherent and relevant answers compared to individual large language models.\\n\\nKey differences:\\n\\n*   **Focus**: LangChain has a broader focus on hybrid intelligence, while LangSmith is specifically designed for improving the robustness of language understanding systems.\\n*   **Integration**: LangChain allows developers to combine different AI techniques, whereas LangSmith focuses on combining multiple pre-trained language models.\\n*   **Application scope**: LangChain is suitable for a wider range of applications (e.g., NLP, computer vision, robotics), while LangSmith is specifically tailored for tasks requiring robust and accurate language understanding.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "# Verifica che Ollama sia in esecuzione\n",
    "chat_model = OllamaLLM(model=\"llama3.1:8b\")\n",
    "\n",
    "chat_model.invoke([\n",
    "    HumanMessage(\"What's the difference between LangSmith and LangChain?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca336bcd-65e6-4fbc-99ac-ab48b610b3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "joke_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class comedian.\"),\n",
    "    (\"human\", \"Tell me a joke about {topic}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c12fc2b2-7e21-4f1b-900e-1b03dc5fae5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a world class comedian.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about beets', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_prompt.invoke({\"topic\": \"beets\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55091a-5137-4660-8f34-48556dedf04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
